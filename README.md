# ML-Programming-Task

I broke up this task into two parts: the NLP portion (1.1/1.3) and the machine learning portion (1.2).

For both, I started off with processing the validated.tsv dataset to isolate the first 100 clips for the NLP, and the first 1000 clips with the "male" or "female" gender labels to train the model.

For the NLP portion I found the Word Error Rate of the Whisper Model by implementing my own function that calculated the distance from each word in the hypothesis sentence (Whisper model) to each word in the reference sentence (ground truth given the validated dataset). I used the formula (insertions + deletions + substitutions)/number of words to calculate the WER as a percentage, applied to each pair of clips in the dataset, and calculated the mean error which was 15.36%. The Whisper model is said to have a word error rate of around 10%, and considering that I only had 100 data points, I was not too far off. I also found the cosine similarity of all the clips to one another, by vectorizing them, and the using the cosine_similairty functions from sklearn. All the cosine similarities were stored in a matrix, and with this information, we can group the clips together based on the ones that have a high cosine similarity. Next, I found the 100 most common words using the NLTK library which has a lot of NLP algorithms. The top five most common words were "the", "of", "and", "The", and "to", which makes sense because all of these words are used very frequently in English as they are conjuection words. Then, I found the sentiment scores for each clip, and I included both the polarity of the clips and the sbjectivity, which gives how negative or positive the statement is and how biased the statement is, respectively. Finally, I found the token-type ratio which basically gives the diversity in vocabulary of the clips. Type-token ratio gives the ratio between the number of unique words and the total number of words. For all ten groups, the TTR was very high, but the clips were also very short in length so the TTR becomes less meaningful. 

For the machine leanring portion, I had to create a model that predicted the gender of the speaker in the clip. The first step was thec create a dataset to train the model on. I used the librosa library to pull a lot of acoustic data, and once I had the dataframe with all the feature data and the target labels, I had to choose what kind of model I wanted to use. I had 3 options, logistic regression, random forest tree, and a neural network. I didn't choose logistic regression because it had the risk of over-fitting to the dataset, and I didn't choose a neural network because I felt that I did not have enough data to train the model. So I traied the random forst classifier and got an accuracy score of 87.50% which is pretty good. I also generated the confusion matrix and the ROC curve. I had an ROC curve area of 0.95 which is considered very good. 
 
